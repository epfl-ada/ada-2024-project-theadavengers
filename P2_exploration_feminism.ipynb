{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2 Exploration\n",
    "\n",
    "Basic exploration will be done in this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import pandas as pd\n",
    " \n",
    "# Just fill this with wherever is your main data folder is (copy the path just before 'MovieSummaries'):\n",
    "file_source = \"/Users/shrinidhivelan/Downloads/\"\n",
    "\n",
    "# Same goes for the reviews dataset : but simply copy the entire path of where your reviews data is... \n",
    "reviews_path = \"/Users/shrinidhivelan/Downloads/TMDB_movie_dataset_v11.csv\"\n",
    "\n",
    "# replace the following by the direct path of where your bechdel test movie data is:\n",
    "bechdel_path = \"/Users/shrinidhivelan/Downloads/movies.csv\"\n",
    "\n",
    "### creating dataset by extracting \n",
    "MovieMetadata_df, CharacterMetadata_df, names_df, plot_summaries_df, tvTropes_df, merged_df = create_datasets(file_source, reviews_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We merge the data on the bechdel test : \n",
    "There are more lines as some movies occur twice (redone) in the movieMetadata dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>binary</th>\n",
       "      <th>budget</th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Freebase movie ID</th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Movie release date</th>\n",
       "      <th>Movie box office revenue</th>\n",
       "      <th>Movie runtime</th>\n",
       "      <th>Movie languages (Freebase ID:name tuples)</th>\n",
       "      <th>Movie countries (Freebase ID:name tuples)</th>\n",
       "      <th>Movie genres (Freebase ID:name tuples)</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>42</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>40000000</td>\n",
       "      <td>36239136.0</td>\n",
       "      <td>/m/0k2jpkj</td>\n",
       "      <td>42</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01z02hx\": \"Sports\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>47 Ronin</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>225000000</td>\n",
       "      <td>32806120.0</td>\n",
       "      <td>/m/0h3rn9v</td>\n",
       "      <td>47 Ronin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/03_3d\": \"Japan\"}</td>\n",
       "      <td>{\"/m/0gw5n2f\": \"Japanese Movies\"}</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>47 Ronin</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>225000000</td>\n",
       "      <td>29769606.0</td>\n",
       "      <td>/m/0fp_dsj</td>\n",
       "      <td>47 Ronin</td>\n",
       "      <td>2012-11-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\", \"/m/02kdv5l\": \"Action\"...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>A Good Day to Die Hard</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>92000000</td>\n",
       "      <td>34228306.0</td>\n",
       "      <td>/m/0hhgg_1</td>\n",
       "      <td>A Good Day to Die Hard</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/01jfsb\": \"Th...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>After Earth</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>130000000</td>\n",
       "      <td>34429259.0</td>\n",
       "      <td>/m/0hhgh70</td>\n",
       "      <td>After Earth</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\", \"/m/...</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/02kdv5l\": ...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>1971</td>\n",
       "      <td>Shaft</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>53012938</td>\n",
       "      <td>973155.0</td>\n",
       "      <td>/m/03vpf7</td>\n",
       "      <td>Shaft</td>\n",
       "      <td>2000-06-16</td>\n",
       "      <td>107196498.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\", \"/m/04306rv...</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\", \"/m/...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0lsxr\": \"Crime F...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>1971</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>25000000</td>\n",
       "      <td>196176.0</td>\n",
       "      <td>/m/01bwgr</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>1971-11-03</td>\n",
       "      <td>11148828.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\", \"/m/...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/07s9rl0\": \"Drama\"}</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>1971</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>25000000</td>\n",
       "      <td>29657080.0</td>\n",
       "      <td>/m/084nr2g</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>2011-09-16</td>\n",
       "      <td>10324441.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/02wtdps\": \"Crime...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>1971</td>\n",
       "      <td>The French Connection</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>2200000</td>\n",
       "      <td>99463.0</td>\n",
       "      <td>/m/0pd64</td>\n",
       "      <td>The French Connection</td>\n",
       "      <td>1971-10-07</td>\n",
       "      <td>51700000.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>{\"/m/064_8sq\": \"French Language\", \"/m/02h40lc\"...</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0lsxr\": \"Crime F...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>1970</td>\n",
       "      <td>Beyond the Valley of the Dolls</td>\n",
       "      <td>PASS</td>\n",
       "      <td>1000000</td>\n",
       "      <td>921865.0</td>\n",
       "      <td>/m/03q4p9</td>\n",
       "      <td>Beyond the Valley of the Dolls</td>\n",
       "      <td>1970-06-17</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0gf28\": \"Parody\", \"/m/0220p9g\": \"Musical ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2071 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                           title binary     budget  \\\n",
       "4     2013                              42   FAIL   40000000   \n",
       "5     2013                        47 Ronin   FAIL  225000000   \n",
       "6     2013                        47 Ronin   FAIL  225000000   \n",
       "7     2013          A Good Day to Die Hard   FAIL   92000000   \n",
       "10    2013                     After Earth   FAIL  130000000   \n",
       "...    ...                             ...    ...        ...   \n",
       "2341  1971                           Shaft   FAIL   53012938   \n",
       "2342  1971                      Straw Dogs   FAIL   25000000   \n",
       "2343  1971                      Straw Dogs   FAIL   25000000   \n",
       "2344  1971           The French Connection   FAIL    2200000   \n",
       "2346  1970  Beyond the Valley of the Dolls   PASS    1000000   \n",
       "\n",
       "      Wikipedia movie ID Freebase movie ID                      Movie name  \\\n",
       "4             36239136.0        /m/0k2jpkj                              42   \n",
       "5             32806120.0        /m/0h3rn9v                        47 Ronin   \n",
       "6             29769606.0        /m/0fp_dsj                        47 Ronin   \n",
       "7             34228306.0        /m/0hhgg_1          A Good Day to Die Hard   \n",
       "10            34429259.0        /m/0hhgh70                     After Earth   \n",
       "...                  ...               ...                             ...   \n",
       "2341            973155.0         /m/03vpf7                           Shaft   \n",
       "2342            196176.0         /m/01bwgr                      Straw Dogs   \n",
       "2343          29657080.0        /m/084nr2g                      Straw Dogs   \n",
       "2344             99463.0          /m/0pd64           The French Connection   \n",
       "2346            921865.0         /m/03q4p9  Beyond the Valley of the Dolls   \n",
       "\n",
       "     Movie release date  Movie box office revenue  Movie runtime  \\\n",
       "4            2013-04-12                       NaN            NaN   \n",
       "5                   NaN                       NaN          132.0   \n",
       "6            2012-11-21                       NaN            NaN   \n",
       "7            2013-02-14                       NaN            NaN   \n",
       "10           2013-06-07                       NaN            NaN   \n",
       "...                 ...                       ...            ...   \n",
       "2341         2000-06-16               107196498.0           99.0   \n",
       "2342         1971-11-03                11148828.0          118.0   \n",
       "2343         2011-09-16                10324441.0          110.0   \n",
       "2344         1971-10-07                51700000.0          104.0   \n",
       "2346         1970-06-17                 9000000.0          109.0   \n",
       "\n",
       "              Movie languages (Freebase ID:name tuples)  \\\n",
       "4                    {\"/m/02h40lc\": \"English Language\"}   \n",
       "5                                                    {}   \n",
       "6                    {\"/m/02h40lc\": \"English Language\"}   \n",
       "7                    {\"/m/02h40lc\": \"English Language\"}   \n",
       "10                   {\"/m/02h40lc\": \"English Language\"}   \n",
       "...                                                 ...   \n",
       "2341  {\"/m/02h40lc\": \"English Language\", \"/m/04306rv...   \n",
       "2342                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "2343                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "2344  {\"/m/064_8sq\": \"French Language\", \"/m/02h40lc\"...   \n",
       "2346                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "              Movie countries (Freebase ID:name tuples)  \\\n",
       "4             {\"/m/09c7w0\": \"United States of America\"}   \n",
       "5                                 {\"/m/03_3d\": \"Japan\"}   \n",
       "6             {\"/m/09c7w0\": \"United States of America\"}   \n",
       "7             {\"/m/09c7w0\": \"United States of America\"}   \n",
       "10    {\"/m/09c7w0\": \"United States of America\", \"/m/...   \n",
       "...                                                 ...   \n",
       "2341  {\"/m/09c7w0\": \"United States of America\", \"/m/...   \n",
       "2342  {\"/m/09c7w0\": \"United States of America\", \"/m/...   \n",
       "2343          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2344          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2346          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "\n",
       "                 Movie genres (Freebase ID:name tuples)  Year  \n",
       "4     {\"/m/01z02hx\": \"Sports\", \"/m/03bxz7\": \"Biograp...  2013  \n",
       "5                     {\"/m/0gw5n2f\": \"Japanese Movies\"}  <NA>  \n",
       "6     {\"/m/07s9rl0\": \"Drama\", \"/m/02kdv5l\": \"Action\"...  2012  \n",
       "7     {\"/m/0lsxr\": \"Crime Fiction\", \"/m/01jfsb\": \"Th...  2013  \n",
       "10    {\"/m/06n90\": \"Science Fiction\", \"/m/02kdv5l\": ...  2013  \n",
       "...                                                 ...   ...  \n",
       "2341  {\"/m/01jfsb\": \"Thriller\", \"/m/0lsxr\": \"Crime F...  2000  \n",
       "2342   {\"/m/01jfsb\": \"Thriller\", \"/m/07s9rl0\": \"Drama\"}  1971  \n",
       "2343  {\"/m/01jfsb\": \"Thriller\", \"/m/02wtdps\": \"Crime...  2011  \n",
       "2344  {\"/m/01jfsb\": \"Thriller\", \"/m/0lsxr\": \"Crime F...  1971  \n",
       "2346  {\"/m/0gf28\": \"Parody\", \"/m/0220p9g\": \"Musical ...  1970  \n",
       "\n",
       "[2071 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The bechdel data contains ~1700 lines, to be separated into train and test sets in order to create a model to predict the binary result\n",
    "#### 80% train and 20% test for instance, this will be used to merge main data into this : \n",
    "bechdel_data = pd.read_csv(bechdel_path)\n",
    "bechdel_data = bechdel_data[['year', 'title', 'binary','budget']]\n",
    "bechdel_data_merged = bechdel_data.merge(MovieMetadata_df, how='left', left_on = 'title', right_on = 'Movie name')\n",
    "\n",
    "# Define the columns to check for NaN values\n",
    "columns_to_check = [\n",
    "    'Wikipedia movie ID', 'Freebase movie ID', 'Movie name', \n",
    "    'Movie release date', 'Movie box office revenue', 'Movie runtime', \n",
    "    'Movie languages (Freebase ID:name tuples)', \n",
    "    'Movie countries (Freebase ID:name tuples)', \n",
    "    'Movie genres (Freebase ID:name tuples)'\n",
    "]\n",
    "\n",
    "# Remove rows where all specified columns are NaN\n",
    "bechdel_data_merged = bechdel_data_merged.dropna(subset=columns_to_check, how='all')\n",
    "\n",
    "# Display the DataFrame to confirm rows are removed - around ~300 lines are removed\n",
    "display(bechdel_data_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/m1p5k4zj0yn9mk66d_dh7pn40000gn/T/ipykernel_24135/3015687340.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['result'] = df['binary'].replace({'FAIL': 0, 'PASS': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n",
      "F1 Score: 0.46\n",
      "ROC AUC Score: 0.59\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "df = bechdel_data_merged  \n",
    "\n",
    "# Specify the target and feature columns\n",
    "target = 'result'\n",
    "features = [\n",
    "    'year', 'budget', 'Wikipedia movie ID', 'Freebase movie ID', 'Movie name', \n",
    "    'Movie release date', 'Movie box office revenue', 'Movie runtime', \n",
    "    'Movie languages (Freebase ID:name tuples)', 'Movie countries (Freebase ID:name tuples)', \n",
    "    'Movie genres (Freebase ID:name tuples)', 'Year'\n",
    "]\n",
    "\n",
    "# Convert 'FAIL' to 0 and 'PASS' to 1 in the 'binary' column\n",
    "df['result'] = df['binary'].replace({'FAIL': 0, 'PASS': 1})\n",
    "\n",
    "\n",
    "# Drop rows where target is NaN\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Separate features and target variable (X and y constantly)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Step 2: Preprocess features\n",
    "# Define which columns need specific preprocessing\n",
    "numeric_features = ['year', 'budget', 'Movie box office revenue', 'Movie runtime', 'Year']\n",
    "categorical_features = [\n",
    "    'Wikipedia movie ID', 'Freebase movie ID', 'Movie name', \n",
    "    'Movie languages (Freebase ID:name tuples)', 'Movie countries (Freebase ID:name tuples)', \n",
    "    'Movie genres (Freebase ID:name tuples)'\n",
    "]\n",
    "\n",
    "# Define preprocessors\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 3: Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)#, random_state=42)\n",
    "\n",
    "# Step 4: Define and train the model pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier())])#(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries_df\n",
    "plot_summaries_df_merged = plot_summaries_df.merge(MovieMetadata_df, how='left', left_on = 'Wikipedia movie ID', right_on = 'Wikipedia movie ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>binary</th>\n",
       "      <th>budget</th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Summaries</th>\n",
       "      <th>Freebase movie ID</th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Movie release date</th>\n",
       "      <th>Movie box office revenue</th>\n",
       "      <th>Movie runtime</th>\n",
       "      <th>Movie languages (Freebase ID:name tuples)</th>\n",
       "      <th>Movie countries (Freebase ID:name tuples)</th>\n",
       "      <th>Movie genres (Freebase ID:name tuples)</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>47 Ronin</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>225000000</td>\n",
       "      <td>29769606.0</td>\n",
       "      <td>{{main}} The outcast Kai  joins a group of Sam...</td>\n",
       "      <td>/m/0fp_dsj</td>\n",
       "      <td>47 Ronin</td>\n",
       "      <td>2012-11-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\", \"/m/02kdv5l\": \"Action\"...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>After Earth</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>130000000</td>\n",
       "      <td>34429259.0</td>\n",
       "      <td>One thousand years after cataclysmic events fo...</td>\n",
       "      <td>/m/0hhgh70</td>\n",
       "      <td>After Earth</td>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\", \"/m/...</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/02kdv5l\": ...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>American Hustle</td>\n",
       "      <td>PASS</td>\n",
       "      <td>40000000</td>\n",
       "      <td>15697462.0</td>\n",
       "      <td>Katt Williams decides that he wants to make it...</td>\n",
       "      <td>/m/03nqd13</td>\n",
       "      <td>American Hustle</td>\n",
       "      <td>2007-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01z4y\": \"Comedy\"}</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013</td>\n",
       "      <td>August: Osage County</td>\n",
       "      <td>PASS</td>\n",
       "      <td>25000000</td>\n",
       "      <td>37210334.0</td>\n",
       "      <td>The movie is based upon a play by the same nam...</td>\n",
       "      <td>/m/0n52lw7</td>\n",
       "      <td>August: Osage County</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/05p553\": \"Comedy film\", \"/m/07s9rl0\": \"Dr...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013</td>\n",
       "      <td>Carrie</td>\n",
       "      <td>PASS</td>\n",
       "      <td>30000000</td>\n",
       "      <td>6584119.0</td>\n",
       "      <td>{{Plot}} Carrie Meeber ([[Jennifer Jones  leav...</td>\n",
       "      <td>/m/0gcn0w</td>\n",
       "      <td>Carrie</td>\n",
       "      <td>1952-07-17</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/068d7h\": \"Romantic drama\", \"/m/02l7c8\": \"...</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>1971</td>\n",
       "      <td>Shaft</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>53012938</td>\n",
       "      <td>76345.0</td>\n",
       "      <td>{{Plot}} Shaft, a private detective, emerges f...</td>\n",
       "      <td>/m/0k47y</td>\n",
       "      <td>Shaft</td>\n",
       "      <td>1971-06-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\", \"/m/0t_2\": ...</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/01jfsb\": \"Th...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>1971</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>25000000</td>\n",
       "      <td>29657080.0</td>\n",
       "      <td>Los Angeles scriptwriter David Sumner  and his...</td>\n",
       "      <td>/m/084nr2g</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>2011-09-16</td>\n",
       "      <td>10324441.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/02wtdps\": \"Crime...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>1971</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>25000000</td>\n",
       "      <td>196176.0</td>\n",
       "      <td>David Sumner , a timid American mathematician,...</td>\n",
       "      <td>/m/01bwgr</td>\n",
       "      <td>Straw Dogs</td>\n",
       "      <td>1971-11-03</td>\n",
       "      <td>11148828.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\", \"/m/...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/07s9rl0\": \"Drama\"}</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>1971</td>\n",
       "      <td>The French Connection</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>2200000</td>\n",
       "      <td>99463.0</td>\n",
       "      <td>The film revolves around the smuggling of narc...</td>\n",
       "      <td>/m/0pd64</td>\n",
       "      <td>The French Connection</td>\n",
       "      <td>1971-10-07</td>\n",
       "      <td>51700000.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>{\"/m/064_8sq\": \"French Language\", \"/m/02h40lc\"...</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0lsxr\": \"Crime F...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>1970</td>\n",
       "      <td>Beyond the Valley of the Dolls</td>\n",
       "      <td>PASS</td>\n",
       "      <td>1000000</td>\n",
       "      <td>921865.0</td>\n",
       "      <td>Three young women &amp;mdash; Kelly MacNamara , Ca...</td>\n",
       "      <td>/m/03q4p9</td>\n",
       "      <td>Beyond the Valley of the Dolls</td>\n",
       "      <td>1970-06-17</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0gf28\": \"Parody\", \"/m/0220p9g\": \"Musical ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1784 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                           title binary     budget  \\\n",
       "5     2013                        47 Ronin   FAIL  225000000   \n",
       "9     2013                     After Earth   FAIL  130000000   \n",
       "10    2013                 American Hustle   PASS   40000000   \n",
       "11    2013            August: Osage County   PASS   25000000   \n",
       "15    2013                          Carrie   PASS   30000000   \n",
       "...    ...                             ...    ...        ...   \n",
       "2106  1971                           Shaft   FAIL   53012938   \n",
       "2107  1971                      Straw Dogs   FAIL   25000000   \n",
       "2108  1971                      Straw Dogs   FAIL   25000000   \n",
       "2109  1971           The French Connection   FAIL    2200000   \n",
       "2111  1970  Beyond the Valley of the Dolls   PASS    1000000   \n",
       "\n",
       "      Wikipedia movie ID                                          Summaries  \\\n",
       "5             29769606.0  {{main}} The outcast Kai  joins a group of Sam...   \n",
       "9             34429259.0  One thousand years after cataclysmic events fo...   \n",
       "10            15697462.0  Katt Williams decides that he wants to make it...   \n",
       "11            37210334.0  The movie is based upon a play by the same nam...   \n",
       "15             6584119.0  {{Plot}} Carrie Meeber ([[Jennifer Jones  leav...   \n",
       "...                  ...                                                ...   \n",
       "2106             76345.0  {{Plot}} Shaft, a private detective, emerges f...   \n",
       "2107          29657080.0  Los Angeles scriptwriter David Sumner  and his...   \n",
       "2108            196176.0  David Sumner , a timid American mathematician,...   \n",
       "2109             99463.0  The film revolves around the smuggling of narc...   \n",
       "2111            921865.0  Three young women &mdash; Kelly MacNamara , Ca...   \n",
       "\n",
       "     Freebase movie ID                      Movie name Movie release date  \\\n",
       "5           /m/0fp_dsj                        47 Ronin         2012-11-21   \n",
       "9           /m/0hhgh70                     After Earth         2013-06-07   \n",
       "10          /m/03nqd13                 American Hustle         2007-06-01   \n",
       "11          /m/0n52lw7            August: Osage County               2013   \n",
       "15           /m/0gcn0w                          Carrie         1952-07-17   \n",
       "...                ...                             ...                ...   \n",
       "2106          /m/0k47y                           Shaft         1971-06-25   \n",
       "2107        /m/084nr2g                      Straw Dogs         2011-09-16   \n",
       "2108         /m/01bwgr                      Straw Dogs         1971-11-03   \n",
       "2109          /m/0pd64           The French Connection         1971-10-07   \n",
       "2111         /m/03q4p9  Beyond the Valley of the Dolls         1970-06-17   \n",
       "\n",
       "      Movie box office revenue  Movie runtime  \\\n",
       "5                          NaN            NaN   \n",
       "9                          NaN            NaN   \n",
       "10                         NaN            NaN   \n",
       "11                         NaN            NaN   \n",
       "15                   1800000.0          118.0   \n",
       "...                        ...            ...   \n",
       "2106                       NaN           98.0   \n",
       "2107                10324441.0          110.0   \n",
       "2108                11148828.0          118.0   \n",
       "2109                51700000.0          104.0   \n",
       "2111                 9000000.0          109.0   \n",
       "\n",
       "              Movie languages (Freebase ID:name tuples)  \\\n",
       "5                    {\"/m/02h40lc\": \"English Language\"}   \n",
       "9                    {\"/m/02h40lc\": \"English Language\"}   \n",
       "10                   {\"/m/02h40lc\": \"English Language\"}   \n",
       "11                                                   {}   \n",
       "15                   {\"/m/02h40lc\": \"English Language\"}   \n",
       "...                                                 ...   \n",
       "2106  {\"/m/02h40lc\": \"English Language\", \"/m/0t_2\": ...   \n",
       "2107                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "2108                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "2109  {\"/m/064_8sq\": \"French Language\", \"/m/02h40lc\"...   \n",
       "2111                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "              Movie countries (Freebase ID:name tuples)  \\\n",
       "5             {\"/m/09c7w0\": \"United States of America\"}   \n",
       "9     {\"/m/09c7w0\": \"United States of America\", \"/m/...   \n",
       "10            {\"/m/09c7w0\": \"United States of America\"}   \n",
       "11            {\"/m/09c7w0\": \"United States of America\"}   \n",
       "15            {\"/m/09c7w0\": \"United States of America\"}   \n",
       "...                                                 ...   \n",
       "2106          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2107          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2108  {\"/m/09c7w0\": \"United States of America\", \"/m/...   \n",
       "2109          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2111          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "\n",
       "                 Movie genres (Freebase ID:name tuples)  Year  \n",
       "5     {\"/m/07s9rl0\": \"Drama\", \"/m/02kdv5l\": \"Action\"...  2012  \n",
       "9     {\"/m/06n90\": \"Science Fiction\", \"/m/02kdv5l\": ...  2013  \n",
       "10                               {\"/m/01z4y\": \"Comedy\"}  2007  \n",
       "11    {\"/m/05p553\": \"Comedy film\", \"/m/07s9rl0\": \"Dr...  2013  \n",
       "15    {\"/m/068d7h\": \"Romantic drama\", \"/m/02l7c8\": \"...  1952  \n",
       "...                                                 ...   ...  \n",
       "2106  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/01jfsb\": \"Th...  1971  \n",
       "2107  {\"/m/01jfsb\": \"Thriller\", \"/m/02wtdps\": \"Crime...  2011  \n",
       "2108   {\"/m/01jfsb\": \"Thriller\", \"/m/07s9rl0\": \"Drama\"}  1971  \n",
       "2109  {\"/m/01jfsb\": \"Thriller\", \"/m/0lsxr\": \"Crime F...  1971  \n",
       "2111  {\"/m/0gf28\": \"Parody\", \"/m/0220p9g\": \"Musical ...  1970  \n",
       "\n",
       "[1784 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_summaries_df_merged\n",
    "\n",
    "# The bechdel data contains ~1700 lines, to be separated into train and test sets in order to create a model to predict the binary result\n",
    "#### 80% train and 20% test for instance, this will be used to merge main data into this : \n",
    "bechdel_data = pd.read_csv(bechdel_path)\n",
    "bechdel_data = bechdel_data[['year', 'title', 'binary','budget']]\n",
    "bechdel_data_merged_new = bechdel_data.merge(plot_summaries_df_merged, how='left', left_on = 'title', right_on = 'Movie name')\n",
    "\n",
    "# Define the columns to check for NaN values\n",
    "columns_to_check = [\n",
    "    'Wikipedia movie ID', 'Freebase movie ID', 'Movie name', \n",
    "    'Movie release date', 'Movie box office revenue', 'Movie runtime', \n",
    "    'Movie languages (Freebase ID:name tuples)', \n",
    "    'Movie countries (Freebase ID:name tuples)', \n",
    "    'Movie genres (Freebase ID:name tuples)'\n",
    "]\n",
    "\n",
    "# Remove rows where all specified columns are NaN\n",
    "bechdel_data_merged_new = bechdel_data_merged_new.dropna(subset=columns_to_check, how='all')\n",
    "\n",
    "# Display the DataFrame to confirm rows are removed - around ~300 lines are removed\n",
    "display(bechdel_data_merged_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/m1p5k4zj0yn9mk66d_dh7pn40000gn/T/ipykernel_24135/2056479736.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['result'] = df['binary'].replace({'FAIL': 0, 'PASS': 1})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SummariesMovie languages (Freebase ID:name tuples)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/utils/_indexing.py:361\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 361\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SummariesMovie languages (Freebase ID:name tuples)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 68\u001b[0m\n\u001b[1;32m     64\u001b[0m model2 \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     65\u001b[0m                         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier())])\u001b[38;5;66;03m#(random_state=42))])\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m model2\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Step 5: Evaluate the model\u001b[39;00m\n\u001b[1;32m     71\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, routed_params)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    407\u001b[0m     cloned_transformer,\n\u001b[1;32m    408\u001b[0m     X,\n\u001b[1;32m    409\u001b[0m     y,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    411\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[1;32m    413\u001b[0m     params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1314\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:968\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m    966\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:536\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    534\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    535\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 536\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m _get_column_indices(X, columns)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/miniconda3/envs/ada/lib/python3.11/site-packages/sklearn/utils/_indexing.py:369\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    366\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "df = bechdel_data_merged_new  \n",
    "\n",
    "# Specify the target and feature columns\n",
    "target = 'result'\n",
    "features = [\n",
    "    'year', 'budget', 'Wikipedia movie ID', 'Freebase movie ID', 'Movie name', \n",
    "    'Movie release date', 'Movie box office revenue', 'Movie runtime', \n",
    "    'Movie languages (Freebase ID:name tuples)', 'Movie countries (Freebase ID:name tuples)', \n",
    "    'Movie genres (Freebase ID:name tuples)', 'Year', 'Summaries'\n",
    "]\n",
    "\n",
    "# Convert 'FAIL' to 0 and 'PASS' to 1 in the 'binary' column\n",
    "df['result'] = df['binary'].replace({'FAIL': 0, 'PASS': 1})\n",
    "\n",
    "\n",
    "# Drop rows where target is NaN\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Separate features and target variable (X and y constantly)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Step 2: Preprocess features\n",
    "# Define which columns need specific preprocessing\n",
    "numeric_features = ['year', 'budget', 'Movie box office revenue', 'Movie runtime', 'Year']\n",
    "categorical_features = [\n",
    "    'Wikipedia movie ID', 'Freebase movie ID', 'Movie name', 'Summaries'\n",
    "    , 'Movie countries (Freebase ID:name tuples)', \n",
    "    'Movie genres (Freebase ID:name tuples)'\n",
    "]\n",
    "\n",
    "# Define preprocessors\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 3: Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)#, random_state=42)\n",
    "\n",
    "# Step 4: Define and train the model pipeline\n",
    "model2 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier())])#(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = model2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
